import numpy as np
import torch
import torch.nn.functional as F
import torch.nn as nn
import imageio
import os

class PairConsecutiveFramesDataset(torch.utils.data.Dataset):
  def __init__(self, root_dir):
    self.num_images = len(os.listdir(root_dir))
    self.root_dir = root_dir

  def __len__(self):
    return self.num_images - 1 # -1 since we load pairs
  
  def __getitem__(self, idx):
    im_1 = torch.tensor(imageio.imread(f'{self.root_dir}/image{idx}.png'), dtype=torch.float32)
    im_2 = torch.tensor(imageio.imread(f'{self.root_dir}/image{idx+1}.png'), dtype=torch.float32)
    return torch.cat((im_1, im_2), dim=-1).transpose(-1,0)

class SfMNet(torch.nn.Module):
  """ SfMNet is a motion detected based off a paper

  This module is desgined for inputs with shape (6,288,512)
  The 6 input channels come from two 3 channel images concatenated
  along the 3rd dimension 

  H,W must be divisible by 2**factor
  """
  def __init__(self, K=1):
    super(SfMNet, self).__init__()
    self.factor = 2
    self.C = 8
    self.K = K
    conv_encode = nn.ModuleList([nn.Conv2d(6, self.C, kernel_size=3, stride=1, padding=1)])
    bns_encode = nn.ModuleList([nn.BatchNorm2d(self.C)])
    # Out channels is at most 2 ** (factor + 5) == 256 for factor == 3
    for i in range(self.factor):
      in_channels = self.C * (2 ** i)
      out_channels = self.C * (2 ** (i + 1))
      conv_encode.append(nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=2, padding=1))
      bns_encode.append(nn.BatchNorm2d(out_channels))
      conv_encode.append(nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1))
      bns_encode.append(nn.BatchNorm2d(out_channels))
    self.conv_encode = conv_encode
    self.bns_encode = bns_encode

    conv_decode = nn.ModuleList([]) # For the decoder
    bns_decode = nn.ModuleList([])
    for i in range(self.factor):
      in_channels = int(self.C * 2 ** (self.factor - i - 1) * 1.5)
      out_channels = self.C * 2 ** (self.factor - i - 1)
      conv_decode.append(nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=1, padding=1))
      bns_decode.append(nn.BatchNorm2d(out_channels))

    self.conv_decode = conv_decode
    self.bns_decode = bns_decode
    self.final_conv = nn.Conv2d(self.C, K, kernel_size=3, stride=1, padding=1)
    self.final_bn = nn.BatchNorm2d(K)

  def forward(self, xs):
    # Compute the embedding using the encoder convolutional layers
    encodings = []
    for i, (conv, bn) in enumerate(zip(self.conv_encode, self.bns_encode)):
      if i % 2 == 1:
        encodings.append(xs)
      xs = F.relu(bn(conv(xs)))

    embedding = torch.reshape(xs, (xs.shape[0], -1)) # Reshape to a flat vector
    assert(len(encodings) == self.factor)

    # Compute object masks using convolutional decoder layers
    for i, (conv, bn) in enumerate(zip(self.conv_decode, self.bns_decode)):
      xs = F.pixel_shuffle(xs, 2)
      xs = torch.cat((xs, encodings[-1-i]), dim=1) # Cat on channel dimension
      xs = F.relu(bn(conv(xs)))

    masks = torch.sigmoid(self.final_bn(self.final_conv(xs)))

    embedding = em

    return xs

ds = PairConsecutiveFramesDataset('../../data/single_red_ball_512x288')
dl = torch.utils.data.DataLoader(ds, batch_size=1, shuffle=True)

model = SfMNet()
optim = torch.optim.Adam(model.parameters())

input = ds[0].unsqueeze(0)
output = model(input)
print(output.shape)
